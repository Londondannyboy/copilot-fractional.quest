# How We Built This: CopilotKit + Pydantic AI Integration Guide

## The Correct Build Order (Lessons Learned)

**Key Insight: Build CopilotKit + Pydantic AI FIRST. Add Hume voice LAST.**

### Phase 1: CopilotKit + Pydantic AI (DO THIS FIRST)

```
Step 1: Scaffold with CopilotKit CLI
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
$ npx copilotkit@latest create -f pydantic-ai

This creates:
â”œâ”€â”€ frontend/          # Next.js with CopilotKit
â”‚   â””â”€â”€ src/app/
â”‚       â””â”€â”€ page.tsx   # Has <CopilotKit>, <CopilotSidebar>
â””â”€â”€ agent/             # Pydantic AI agent
    â””â”€â”€ src/
        â””â”€â”€ agent.py   # Basic agent template
```

```
Step 2: Run both services locally
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Terminal 1: cd frontend && npm run dev     # Port 3000
Terminal 2: cd agent && uv run uvicorn src.agent:app --port 8000
```

```
Step 3: Verify chat works
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
- Open localhost:3000
- Chat should work via CopilotKit sidebar
- Agent responds via AG-UI protocol
```

```
Step 4: Add your tools to agent.py
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@agent.tool
def search_jobs(ctx, query: str) -> dict:
    # Your business logic
    return {"jobs": [...]}
```

```
Step 5: Add useRenderToolCall for Generative UI
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// In frontend
useRenderToolCall({
  name: "search_jobs",
  render: ({ result }) => <JobCards jobs={result.jobs} />
})
```

```
Step 6: Add shared state with useCoAgent
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const { state, setState } = useCoAgent<AppState>({
  name: "agent",
  initialState: { jobs: [], user: null }
})
```

**âœ… CHECKPOINT: Chat works, tools work, Generative UI works. NOW you can add voice.**

### Phase 2: Add Hume Voice (DO THIS SECOND)

```
Step 7: Create Hume account and config
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
- Go to platform.hume.ai
- Create EVI config
- Get Config ID and API keys
```

```
Step 8: Add Hume token endpoint
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// app/api/hume-token/route.ts
// Returns access token for Hume WebSocket
```

```
Step 9: Add voice widget to frontend
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Uses @humeai/voice-react
<VoiceProvider configId={...}>
  <VoiceWidget />
</VoiceProvider>
```

```
Step 10: Create CLM endpoint for Hume
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Hume needs OpenAI-compatible /chat/completions
// Add this to your agent.py (see CLM Consolidation Pattern below)
// OR deploy separate CLM service (not recommended)
```

```
Step 11: Configure Hume to use your CLM
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
- In Hume dashboard, set CLM URL to your deployed agent
- Enable "CLM-only mode" (disable Hume's built-in LLM)
```

### Why This Order Matters

| Order | Result |
|-------|--------|
| âœ… CopilotKit first, Hume second | Chat works, then voice works, same brain |
| âŒ Hume first, CopilotKit second | Voice works but disconnected, debugging nightmare |

**The mistake we made:** We had Hume configured pointing to `simple-clm` before the Pydantic AI agent was deployed. Result: Voice used a dumb fallback while Chat used the smart agent. Different brains = confusion.

---

## CRITICAL: Passing User Context to Pydantic AI Agent

**This is vital knowledge.** CopilotKit's `useCoAgent` state sync (`state.user`) often doesn't work reliably - the agent may see `user: None` even when the frontend has a logged-in user. Here's the bulletproof pattern we discovered:

### The Problem

When using CopilotKit with a Pydantic AI agent:
- Frontend has `user` object from auth (Neon Auth, Stack Auth, etc.)
- Agent `ctx.deps.state.user` is often `None` or missing fields
- Result: "I don't know who you are" when user asks about their profile

### The Solution: Instructions Prop + Middleware

**Step 1: Fetch user profile data on frontend**

```typescript
// page.tsx
const [profileItems, setProfileItems] = useState<{
  location?: string;
  role?: string;
  skills?: string[];
  companies?: string[];
}>({});

useEffect(() => {
  if (!user?.id) return;

  fetch(`/api/user-profile?userId=${user.id}`)
    .then(res => res.json())
    .then(data => {
      const items = data.items || [];
      const grouped = {};
      items.forEach((item) => {
        if (item.item_type === 'location') grouped.location = item.value;
        if (item.item_type === 'role_preference') grouped.role = item.value;
        if (item.item_type === 'skill') {
          if (!grouped.skills) grouped.skills = [];
          grouped.skills.push(item.value);
        }
        if (item.item_type === 'company') {
          if (!grouped.companies) grouped.companies = [];
          grouped.companies.push(item.value);
        }
      });
      setProfileItems(grouped);
    });
}, [user?.id]);
```

**Step 2: Build instructions string with ALL user context**

```typescript
const agentInstructions = user
  ? `CRITICAL USER CONTEXT:
- User Name: ${firstName || user.name}
- User ID: ${user.id}
- User Email: ${user.email}
- Location: ${profileItems.location || 'Not set'}
- Target Role: ${profileItems.role || 'Not set'}
- Skills: ${profileItems.skills?.join(', ') || 'None saved'}
- Companies: ${profileItems.companies?.join(', ') || 'None saved'}

When the user asks about their profile, skills, companies, location, etc., use the above info.`
  : undefined;
```

**Step 3: Pass to CopilotSidebar**

```typescript
<CopilotSidebar
  instructions={agentInstructions}
  // ...other props
>
```

**Step 4: Add middleware to agent.py to extract user context**

```python
# agent/src/agent.py

# Global cache for extracted user context
_cached_user_context: dict = {}

def extract_user_from_instructions(instructions: str) -> dict:
    """Extract user info from CopilotKit instructions text."""
    result = {"user_id": None, "name": None, "email": None}

    if not instructions:
        return result

    import re
    id_match = re.search(r'User ID:\s*([a-f0-9-]+)', instructions, re.IGNORECASE)
    if id_match:
        result["user_id"] = id_match.group(1)

    name_match = re.search(r'User Name:\s*([^\n]+)', instructions, re.IGNORECASE)
    if name_match:
        result["name"] = name_match.group(1).strip()

    email_match = re.search(r'User Email:\s*([^\n]+)', instructions, re.IGNORECASE)
    if email_match:
        result["email"] = email_match.group(1).strip()

    if result["user_id"]:
        global _cached_user_context
        _cached_user_context = result

    return result

def get_effective_user_id(state_user) -> Optional[str]:
    """Get user ID from state or cached instructions."""
    if state_user and state_user.id:
        return state_user.id
    if _cached_user_context.get("user_id"):
        return _cached_user_context["user_id"]
    return None

def get_effective_user_name(state_user) -> Optional[str]:
    """Get user name from state or cached instructions."""
    if state_user and (state_user.firstName or state_user.name):
        return state_user.firstName or state_user.name
    if _cached_user_context.get("name"):
        return _cached_user_context["name"]
    return None
```

**Step 5: Add HTTP middleware to extract before processing**

```python
from fastapi import Request

@main_app.middleware("http")
async def extract_user_middleware(request: Request, call_next):
    """Extract user context from CopilotKit instructions before processing."""
    if request.method == "POST":
        try:
            body_bytes = await request.body()
            if body_bytes:
                body = json.loads(body_bytes)
                messages = body.get("messages", [])
                for msg in messages:
                    role = msg.get("role", "")
                    content = msg.get("content", "")
                    if role == "system" and "User ID:" in content:
                        extracted = extract_user_from_instructions(content)
                        if extracted.get("user_id"):
                            print(f"ğŸ” Middleware extracted user: {extracted.get('name')}")

                # Recreate request with body (since we consumed it)
                async def receive():
                    return {"type": "http.request", "body": body_bytes}
                request = Request(request.scope, receive)
        except Exception as e:
            print(f"[Middleware] Error: {e}")

    return await call_next(request)
```

**Step 6: Use get_effective_user_id() in all tools**

```python
@agent.tool
async def show_user_graph(ctx: RunContext[StateDeps[AppState]]) -> dict:
    user_id = get_effective_user_id(ctx.deps.state.user)
    user_name = get_effective_user_name(ctx.deps.state.user) or "You"

    if not user_id:
        return {"error": "Not logged in"}

    # Now you have reliable user_id for database queries
    ...
```

### Why This Works

1. **Frontend is source of truth** for auth - it has the logged-in user
2. **Instructions prop** is reliably passed as system message to agent
3. **Middleware intercepts** before AG-UI processing, caches user context
4. **Helper functions** provide fallback chain: state.user â†’ cached instructions
5. **All tools** use helpers instead of direct state.user access

### Key Files

| File | Purpose |
|------|---------|
| `src/app/page.tsx` | Fetches profile, builds instructions, passes to CopilotSidebar |
| `agent/src/agent.py` | Middleware + helper functions + tools using helpers |
| `src/app/api/user-profile/route.ts` | API to fetch user profile items from Neon |

### Database Schema for Profile Items

```sql
CREATE TABLE user_profile_items (
  id SERIAL PRIMARY KEY,
  user_id TEXT NOT NULL,
  item_type TEXT NOT NULL,  -- 'location', 'role_preference', 'company', 'skill'
  value TEXT NOT NULL,
  metadata JSONB DEFAULT '{}',
  confirmed BOOLEAN DEFAULT false,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW(),
  UNIQUE(user_id, item_type, value)
);
```

### Common Pitfalls

| Issue | Cause | Fix |
|-------|-------|-----|
| Agent says "I don't know who you are" | Relying on state.user which is null | Use instructions prop + middleware |
| Profile data outdated after update | Instructions not refreshed | Add refresh trigger: `[user?.id, profileRefreshTrigger]` |
| Different data in graph vs profile panel | Graph reading from Zep, panel from Neon | Both should read from Neon |

---

## References Used

### Primary Documentation
| Source | URL | Used For |
|--------|-----|----------|
| **CopilotKit Docs** | https://docs.copilotkit.ai | React components, AG-UI protocol |
| **CopilotKit MCP** | Via Claude Code MCP | Code examples, best practices |
| **Pydantic AI Docs** | https://ai.pydantic.dev | Agent definition, `to_ag_ui()` |
| **Pydantic AI + Vercel** | https://ai.pydantic.dev/ui/vercel-ai/ | VercelAIAdapter (didn't use, but researched) |

### Code References
| Source | URL | Used For |
|--------|-----|----------|
| **CopilotKit GitHub** | https://github.com/CopilotKit/CopilotKit | Example agents, patterns |
| **CopilotKit Examples** | /examples/coagents-starter | FastAPI integration pattern |

### Key Patterns We Used

**1. Pydantic AI Agent Export (from Pydantic AI docs):**
```python
app = agent.to_ag_ui(deps=StateDeps(AppState()))
```

**2. CopilotKit Frontend (from CopilotKit docs):**
```tsx
<CopilotKit runtimeUrl="http://localhost:8000">
  <CopilotSidebar>
    <YourApp />
  </CopilotSidebar>
</CopilotKit>
```

**3. Shared State (from CopilotKit docs):**
```tsx
const { state, setState } = useCoAgent<AppState>({ name: "agent" })
```

**4. Generative UI (from CopilotKit docs):**
```tsx
useRenderToolCall({ name: "tool_name", render: ({ result }) => <Component /> })
```

---

## What NOT to Do

| Mistake | Why It's Bad | What To Do Instead |
|---------|--------------|---------------------|
| Deploy Hume CLM before agent | Voice has no brain to call | Deploy agent first |
| Separate CLM service | Extra complexity, latency | Add CLM endpoint to agent |
| Skip `useRenderToolCall` | Tools return data but UI doesn't show it | Always add renderers |
| Use CopilotRuntime with custom agent | Redundant, conflicts | Use `to_ag_ui()` directly |

---

# Three.js Voice Visualization Learnings

Summary of implementing audio-reactive 3D visuals for a Hume AI voice widget in fractional.quest.

## What We Built

1. **AudioReactiveOrb** - A perfectly round 3D sphere with internal flowing color ripples
2. **EntityGraph3D** - 3D knowledge graph visualization for extracted entities
3. **VoiceWaveform** - Particle-based waveform tunnel effect
4. **VoiceVisualizer** - Unified component that switches between modes

## Key Dependencies

```bash
npm install three @react-three/fiber @react-three/drei @types/three
```

## Architecture

```
HumeWidget3D.tsx          # Fetches Hume token, provides VoiceProvider, extracts FFT
  â””â”€â”€ VoiceVisualizer.tsx # Mode switcher (orb/waveform/graph/combined)
       â””â”€â”€ AudioReactiveOrb.tsx  # Custom GLSL shader orb
       â””â”€â”€ VoiceWaveform.tsx     # Particle tunnel
       â””â”€â”€ EntityGraph3D.tsx     # 3D graph
```

## Critical Learnings

### 1. WebGL Availability
Most users don't have WebGL enabled by default. Always provide CSS fallbacks:

```tsx
function isWebGLAvailable(): boolean {
  if (typeof window === 'undefined') return false
  try {
    const canvas = document.createElement('canvas')
    return !!(window.WebGLRenderingContext &&
      (canvas.getContext('webgl') || canvas.getContext('experimental-webgl')))
  } catch (e) {
    return false
  }
}
```

### 2. SSR Issues with Three.js
Use dynamic imports to avoid SSR problems:

```tsx
const VoiceVisualizer = dynamic(
  () => import('./three/VoiceVisualizer').then(mod => mod.VoiceVisualizer),
  { ssr: false, loading: () => <LoadingPlaceholder /> }
)
```

### 3. Hume FFT Data
The `@humeai/voice-react` hook provides `fft` and `micFft` properties:

```tsx
const { fft, micFft, isPlaying } = useVoice()

// Use assistant FFT when AI is speaking, mic FFT when user speaks
const currentFft = isPlaying ? fft : micFft
```

**WARNING**: Not all Hume configs provide FFT data. You may get empty arrays.

### 4. Converting FFT to Amplitude (0-1)

```tsx
function calculateAmplitude(fftValues: number[] | undefined): number {
  if (!fftValues || fftValues.length === 0) return 0
  let sum = 0
  for (let i = 0; i < fftValues.length; i++) {
    sum += Math.abs(fftValues[i])
  }
  const avg = sum / fftValues.length
  return Math.min(avg / 50, 1)  // Normalize to 0-1
}
```

### 5. Amplitude Smoothing
Raw amplitude is jittery. Always smooth it:

```tsx
// In useFrame or useEffect
smoothedAmplitude.current = smoothedAmplitude.current * 0.85 + rawAmplitude * 0.15
```

### 6. Custom GLSL Shaders for Organic Effects
For Harmony-like flowing colors, use Simplex noise in fragment shader:

```glsl
// Multiple noise layers for flowing color ribbons
float noise1 = snoise(vPosition * 1.2 + vec3(time, time * 0.7, 0.0)) * 0.5 + 0.5;
float noise2 = snoise(vPosition * 1.8 - vec3(time * 0.8, 0.0, time * 0.6)) * 0.5 + 0.5;

// Audio-reactive ripples
float audioRipple = snoise(vPosition * 3.0 + time * rippleSpeed) * amplitude;

// Blend colors
vec3 color = mix(color1, color2, smoothstep(0.2, 0.6, noise1 + audioRipple));
```

### 7. BufferAttribute TypeScript Fix
Don't use individual props, use `args`:

```tsx
// WRONG - causes TypeScript errors
<bufferAttribute attach="attributes-position" count={100} array={positions} itemSize={3} />

// CORRECT
<bufferAttribute attach="attributes-position" args={[positions, 3]} />
```

### 8. useRef TypeScript Fix

```tsx
// WRONG
const ref = useRef<number>()

// CORRECT
const ref = useRef<number | null>(null)
```

## Failures & Debugging

1. **Orb not reacting to audio**: Added console logging to trace FFT data flow:
   ```tsx
   console.log(`[Hume FFT] isPlaying: ${isPlaying}, amplitude: ${amplitude}`)
   ```

2. **Effects too subtle**: Had to increase amplitude multipliers significantly (from 0.1 to 0.25 for scale, etc.)

3. **Harsh geometric look**: Replaced rings with soft glow halos, changed colors from purple to peach/coral palette

4. **Shape distortion unwanted**: User preferred perfectly round orb with internal ripples only - removed vertex displacement from shader

## File Locations (fractional.quest)

- `components/three/AudioReactiveOrb.tsx` - Main orb with GLSL shader
- `components/three/VoiceVisualizer.tsx` - Mode switcher
- `components/three/EntityGraph3D.tsx` - 3D graph
- `components/three/VoiceWaveform.tsx` - Particle waveform
- `components/HumeWidget3D.tsx` - Hume integration wrapper
- `app/voice/page.tsx` - Demo page

## Quick Start for CopilotKit

To add similar visualization:

1. Install deps: `npm install three @react-three/fiber @react-three/drei`
2. Copy the `components/three/` folder from fractional.quest
3. Create a wrapper component that passes amplitude from your audio source
4. Use dynamic import with `ssr: false`
5. Add WebGL fallback for users without GPU acceleration

---

# CopilotKit Demo - Session Learnings (Jan 2025)

## Project Architecture

```
Frontend (Next.js 15)          Backend (FastAPI/Pydantic AI)
â”œâ”€â”€ src/app/page.tsx           â”œâ”€â”€ agent/src/agent.py
â”œâ”€â”€ src/components/            â”‚   â”œâ”€â”€ Tools (search_jobs, show_charts, etc.)
â”‚   â”œâ”€â”€ voice-input.tsx        â”‚   â””â”€â”€ State management
â”‚   â”œâ”€â”€ charts.tsx             â””â”€â”€ Neon PostgreSQL
â”‚   â”œâ”€â”€ ForceGraph3D.tsx
â”‚   â””â”€â”€ a2ui-renderer.tsx
â””â”€â”€ src/app/api/
    â”œâ”€â”€ hume-token/            Hume EVI access tokens
    â”œâ”€â”€ zep-context/           Fetch user memory facts
    â”œâ”€â”€ zep-store/             Store conversation messages
    â””â”€â”€ saved-jobs/            User's saved jobs
```

## Key Integrations

### 1. Hume EVI (Voice)
- **Config ID**: `acb5575c-e22f-44c0-a9c8-b03305d1ea92`
- **Session ID Format**: `{firstName}|fractional_{userId}` for stable sessions
- **Anti-re-greeting**: Track `greetedThisSession` and `lastInteractionTime` to prevent Hume from re-greeting on reconnect

```typescript
// voice-input.tsx pattern
const isQuickReconnect = timeSinceLastInteraction < 5 * 60 * 1000;
if (wasGreeted || isQuickReconnect) {
  // Don't trigger greeting, say "Welcome back!" instead
}
```

### 2. Zep Memory
- **API Key**: Set `ZEP_API_KEY` in `.env`
- **User ID**: Use Neon Auth user ID (e.g., `5e421f23-16a6-42de-a4a4-fa412414f1d8`)
- **Facts are auto-extracted** from conversations (e.g., "CTO roles are sought in London")

**Store messages:**
```typescript
// POST /api/zep-store
{ userId, role: "user"|"assistant", content }
```

**Fetch context:**
```typescript
// GET /api/zep-context?userId=xxx
// Returns: { context: "## What I remember...", facts: [...] }
```

### 3. CopilotKit + AG-UI
- **useRenderToolCall**: Render rich UI for tool results (charts, job cards, graphs)
- **useHumanInTheLoop**: Confirm/reject actions (save job, apply to job)
- **useAgentState**: Sync state between frontend and Pydantic AI agent

### 4. Pydantic AI Agent Tools

| Tool | Purpose | Returns |
|------|---------|---------|
| `search_jobs` | Search job listings | `{ jobs: [...], title, query }` |
| `show_jobs_bar_chart` | Role distribution chart | `{ data: [...], title }` |
| `show_salary_area_chart` | Salary trends | `{ data: [...], title }` |
| `show_market_dashboard` | Full dashboard | `{ stats: {...}, charts: {...} }` |
| `show_user_graph` | 3D force graph of interests | `{ nodes: [...], edges: [...] }` |
| `get_featured_articles` | Related articles | `{ articles: [...] }` |

### 5. 3D Force Graph (react-force-graph-3d)
- **Library**: `react-force-graph-3d` + `three` + `three-spritetext`
- **Node types**: user (center), role, location, skill, interest, fact
- **Colors**: User=gold, Role=blue, Location=green, Skill=purple, Interest=pink
- **File**: `src/components/ForceGraph3D.tsx`

## Common Issues & Solutions

### Issue: Hume re-greets user on every message
**Cause**: Session ID was `Date.now()` based, creating new sessions
**Fix**: Use stable session ID based on userId: `fractional_${userId}`

### Issue: Zep facts not showing in profile
**Cause**: `ZEP_API_KEY` missing from `.env`
**Fix**: Add `ZEP_API_KEY=z_...` to `.env` and restart server

### Issue: Job links return 404
**Cause**: URLs pointed to non-existent `/job/{slug}` pages
**Fix**: Link to existing pages like `fractional.quest/fractional-cto-jobs-uk`

### Issue: Voice messages not stored to Zep
**Cause**: No integration between voice and Zep storage
**Fix**: Call `/api/zep-store` in `handleVoiceMessage` callback (page.tsx)

### Issue: ForceGraph3D SSR error
**Cause**: Three.js doesn't work server-side
**Fix**: Use `dynamic(() => import(...), { ssr: false })`

### Issue: Hume loses context mid-conversation
**Cause**: Hume EVI doesn't persist conversation state between messages
**Fix**: Include Zep context in system prompt on each connect, use stable session IDs

## Environment Variables

```env
# Required
DATABASE_URL=postgresql://...@neon.tech/neondb
HUME_API_KEY=...
HUME_SECRET_KEY=...
ZEP_API_KEY=z_...

# Auth (Neon Auth / Stack Auth)
NEXT_PUBLIC_STACK_PROJECT_ID=...
NEXT_PUBLIC_STACK_PUBLISHABLE_CLIENT_KEY=...
STACK_SECRET_SERVER_KEY=...

# Optional
GOOGLE_API_KEY=...
OPENAI_API_KEY=...
```

## Development Commands

```bash
# Start frontend (Next.js)
npm run dev:ui

# Start backend (Pydantic AI agent)
cd agent && uv run uvicorn src.agent:app --reload --port 8000

# Both together
npm run dev
```

## File Locations

| Feature | Frontend | Backend |
|---------|----------|---------|
| Voice input | `src/components/voice-input.tsx` | - |
| Charts | `src/components/charts.tsx` | `agent/src/agent.py` |
| 3D Graph | `src/components/ForceGraph3D.tsx` | `agent/src/agent.py` |
| Zep integration | `src/app/api/zep-*/route.ts` | `agent/src/agent.py` |
| Job search | `src/app/page.tsx` (renderer) | `agent/src/agent.py` (tool) |
| Profile/Memory | `src/app/profile/page.tsx` | - |

## Testing Checklist

- [ ] Voice connects and greets user by name
- [ ] Reconnecting says "Welcome back!" not re-greeting
- [ ] "Show me CTO jobs" renders job cards with working links
- [ ] "Show my interest graph" renders 3D force graph
- [ ] Profile page shows Zep memory facts
- [ ] Correct/Wrong buttons appear on hover for facts (HITL)

## Related Projects

- `fractional.quest` - Main job board (has ForceGraph3DRepo, reference implementations)
- `lost.london-clm` - Reference for Zep + Hume integration patterns
- `lost.london-app` - Reference for profile/memory dashboard UI

---

# Session Learnings: 2025-01-06

## Voice + CopilotKit + Pydantic AI Sync

### Problem
Hume Voice Widget and CopilotKit/Pydantic AI were out of sync:
- Voice would speak but CopilotKit didn't have the transcript
- When user said "I'm interested in that CTO job", agent didn't know which job
- Human-in-the-loop couldn't work because agent lacked context

### Key Architecture Insight
> "Hume is just an enabler, surely"

Correct! The architecture is:
- **Hume**: Speech-to-text, text-to-speech (I/O layer)
- **CopilotKit**: Message transport, UI rendering
- **Pydantic AI**: THE BRAIN - has DB access, state, tools, Zep memory

### Fixes Applied
1. **Added `last_discussed_job` to AppState** (`agent.py`)
   - Tracks the current job in conversation context
   - Includes full details for "print it" / "apply" actions

2. **Updated `search_jobs` to track context**
   - First job from results becomes `last_discussed_job`
   - Agent knows: "When user says 'that job', they mean THIS job"

---

## SEO Job Pages with Voice + CopilotKit

### Goal
Create job pages that supersede fractional.quest by combining:
- SEO-ranked content (preserved for rankings)
- Hume Voice Agent (contextually aware of page)
- CopilotKit Sidebar (page-aware, showing relevant tools)
- Clean, maintainable code (< 200 lines per file)

### Key Principle
**DO NOT port fractional.quest code.** Rebuild fresh with:
- Global design tokens (single source of truth)
- Templated components
- SEO content in JSON (not inline JSX)

### Components Created
| Location | Files |
|----------|-------|
| `/src/components/ui/` | Section, SectionHeading, StatsBar, JobCard |
| `/src/components/job-pages/` | HeroSection, InitialCharts, JobGrid, SEOContent, FAQSection, JobPageClient |
| `/src/lib/` | jobs.ts, seo-content/london.ts |
| `/src/app/fractional-jobs-london/` | page.tsx |

### Page Context Architecture
```
User lands on /fractional-jobs-london
  â†“
Page sets context in useCoAgent:
  { page_context: { page_type: "jobs_london", location_filter: "London" } }
  â†“
Agent system prompt injects:
  "User is on LONDON JOBS page. When user says 'jobs here', mean London"
```

---

## Build Fixes (Evening Session)

### 1. TypeScript setState Error
**Error**: `prev` could be undefined in setState callback
```typescript
// WRONG
setState(prev => ({ ...prev, user: {...} }));

// CORRECT
setState(prev => ({
  jobs: prev?.jobs ?? [],
  search_query: prev?.search_query ?? "",
  user: {...}
}));
```

### 2. Render Function Returning Null
**Error**: CopilotKit render functions can't return `null`
```typescript
// WRONG
return null;

// CORRECT
return <></>;
```

### 3. Infinite Render Loop
**Cause**: Array dependencies in useEffect get new references each render
```typescript
// WRONG - infinite loop
useEffect(() => {...}, [stats.topRoles, initialJobs]);

// CORRECT
useEffect(() => {...}, [user?.id]);
```

---

## Known Issues (To Fix Next Session)

### 1. Voice Widget Resets
- Voice connects, speaks, then button resets
- Suspected: VoiceProvider remounting on state changes

### 2. CopilotKit Charts Not Rendering
- Agent tools execute (logs show data)
- UI doesn't render results
- Suspected: `useRenderToolCall` missing in JobPageClient.tsx

### Priority Fix
JobPageClient.tsx is likely missing `useRenderToolCall` hooks. Copy from page.tsx.

---

# Session Learnings: 2025-01-06 (Evening) - Production Architecture

## The Three-Service Architecture (Option A)

After debugging why Voice and CopilotKit were out of sync, we established the correct production architecture:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PRODUCTION ARCHITECTURE                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚   â”‚   VERCEL     â”‚         â”‚   VERCEL     â”‚         â”‚  RAILWAY   â”‚ â”‚
â”‚   â”‚  (Next.js)   â”‚         â”‚  (Python)    â”‚         â”‚  (Python)  â”‚ â”‚
â”‚   â”‚              â”‚         â”‚              â”‚         â”‚            â”‚ â”‚
â”‚   â”‚ copilotkit-  â”‚ â”€â”€â”€â”€â”€â”€â–º â”‚  simple-clm  â”‚ â”€â”€â”€â”€â”€â”€â–º â”‚  Pydantic  â”‚ â”‚
â”‚   â”‚ demo.vercel  â”‚         â”‚ .vercel.app  â”‚         â”‚  AI Agent  â”‚ â”‚
â”‚   â”‚              â”‚         â”‚              â”‚         â”‚            â”‚ â”‚
â”‚   â”‚ â€¢ Frontend   â”‚         â”‚ â€¢ CLM for    â”‚         â”‚ â€¢ THE BRAINâ”‚ â”‚
â”‚   â”‚ â€¢ CopilotKit â”‚         â”‚   Hume Voice â”‚         â”‚ â€¢ Tools    â”‚ â”‚
â”‚   â”‚ â€¢ Auth       â”‚         â”‚ â€¢ SSE stream â”‚         â”‚ â€¢ Zep      â”‚ â”‚
â”‚   â”‚              â”‚         â”‚ â€¢ DB fallbackâ”‚         â”‚ â€¢ Neon DB  â”‚ â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚          â”‚                        â–²                       â–²        â”‚
â”‚          â”‚                        â”‚                       â”‚        â”‚
â”‚          â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤        â”‚
â”‚          â”‚    â”‚                   â”‚                       â”‚        â”‚
â”‚          â–¼    â”‚                   â”‚                       â”‚        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚        â”‚
â”‚   â”‚   HUME AI    â”‚ â”€â”€â”€â”€â”€â”€â–º â”‚ CLM Endpoint â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚   â”‚   (Voice)    â”‚         â”‚ /chat/       â”‚                        â”‚
â”‚   â”‚              â”‚         â”‚ completions  â”‚                        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why Three Services?

| Service | Purpose | Why Separate? |
|---------|---------|---------------|
| **copilotkit-demo** (Vercel) | Next.js frontend, auth, API routes | Fast edge deployment, static assets |
| **simple-clm** (Vercel Python) | OpenAI-compatible SSE endpoint for Hume | Hume requires specific CLM format |
| **Pydantic AI Agent** (Railway) | Tools, database, Zep memory, business logic | Long-running Python process, needs Railway |

### The Problem We Solved

**Before**: Hume and CopilotKit were two separate brains
- Hume used its own LLM (would say "I don't have access to personal info")
- CopilotKit used Pydantic AI agent (had all the tools)
- User got different responses depending on voice vs chat

**After**: Single brain (Pydantic AI), two interfaces
- Hume â†’ CLM â†’ Pydantic AI Agent
- CopilotKit â†’ AG-UI â†’ Pydantic AI Agent
- Same tools, same memory, same responses

---

## Onboarding Flow (Added This Session)

### Problem
New users would ask for jobs immediately but agent didn't know their preferences. Result: generic responses.

### Solution
Added proactive onboarding to `agent.py`:

1. **Profile Completeness Check** (`get_user_memory_context`)
   - Returns `(context, is_complete, missing_fields)`
   - Checks Zep facts for: location, role_preference, experience

2. **Dynamic System Prompt Injection**
   - If profile incomplete, injects onboarding instructions
   - Agent asks: "Which city are you based in?" â†’ "What role interests you?" â†’ "Tell me about your experience"

3. **Preference Saving Tool** (`save_user_preference`)
   - When user says "I'm in London", agent calls `save_user_preference("location", "London")`
   - Stored to Zep, auto-extracted as fact

### Code Pattern
```python
# In agent.py system prompt
if not profile_complete and missing_fields:
    prompt_parts.append(f"""
## ONBOARDING MODE - Profile Incomplete!
This user's profile is missing: {', '.join(missing_fields)}

CRITICAL: Before recommending jobs, you MUST gather this info naturally.
First question to ask: "{onboarding_prompts.get(first_missing)}"
""")
```

---

## CLM (Custom Language Model) Deep Dive

### What is CLM?
Hume EVI uses a "Custom Language Model" endpoint instead of its built-in LLM. This allows you to:
- Use your own AI (Pydantic AI, OpenAI, Claude, etc.)
- Inject context (user profile, page info, memory)
- Control tool execution

### CLM Requirements
1. **Endpoint**: OpenAI-compatible `/chat/completions`
2. **Format**: Must return SSE (Server-Sent Events), NOT JSON
3. **Response**: `data: {"choices": [{"delta": {"content": "..."}}]}\n\n`

### simple-clm Architecture
```python
# /Users/dankeegan/simple-clm/api/index.py

async def stream_response(content: str, msg_id: str):
    """Stream OpenAI-compatible SSE chunks - required by Hume EVI."""
    words = content.split(' ')
    for i, word in enumerate(words):
        chunk = {
            "id": msg_id,
            "object": "chat.completion.chunk",
            "choices": [{
                "index": 0,
                "delta": {"content": word + ' '},
                "finish_reason": None
            }]
        }
        yield f"data: {json.dumps(chunk)}\n\n"
    yield "data: [DONE]\n\n"

# Return StreamingResponse, NOT JSONResponse!
return StreamingResponse(stream_response(text, msg_id), media_type="text/event-stream")
```

### Hume Config
- **Config ID**: `acb5575c-e22f-44c0-a9c8-b03305d1ea92`
- **CLM URL**: `https://simple-clm.vercel.app/chat/completions`
- **IMPORTANT**: Disable "Fallback to Hume LLM" in dashboard to ensure CLM-only mode

---

## Railway Deployment Plan

### Files Needed for Agent Deployment

```
/agent/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ agent.py          # Pydantic AI agent with tools
â”œâ”€â”€ pyproject.toml        # Dependencies
â”œâ”€â”€ Procfile              # Railway start command
â””â”€â”€ railway.json          # Railway config (optional)
```

### Procfile
```
web: uvicorn src.agent:app --host 0.0.0.0 --port $PORT
```

### Environment Variables (Railway)
```
DATABASE_URL=postgresql://...@neon.tech/neondb
ZEP_API_KEY=z_...
GOOGLE_API_KEY=...  # For Gemini model
```

### Deployment Steps
1. Create Railway project (or use existing `fractional-quest-agent`)
2. Link to GitHub repo subdirectory `/agent`
3. Set environment variables
4. Deploy and get public URL
5. Update `simple-clm` to call Railway URL instead of localhost

---

## Key Files Modified This Session

| File | Changes |
|------|---------|
| `agent/src/agent.py` | Added onboarding flow, `save_user_preference` tool, profile completeness check |
| `simple-clm/api/index.py` | SSE streaming, personalization, page context |
| `CLAUDE.md` | This documentation |

---

## Next Steps

1. **Deploy Agent to Railway**
   - Create Procfile
   - Set env vars
   - Get public URL

2. **Update simple-clm**
   - Change agent URL from localhost to Railway
   - Redeploy to Vercel

3. **Configure Hume Dashboard**
   - Ensure CLM-only mode (no fallback)
   - Verify config ID matches

4. **Test Full Flow**
   - Voice â†’ CLM â†’ Agent â†’ Response
   - Chat â†’ AG-UI â†’ Agent â†’ Response
   - Both should give identical answers

---

## Debugging Tips

### Check if Agent is Responding
```bash
curl -X POST https://your-railway-app.up.railway.app/ \
  -H "Content-Type: application/json" \
  -d '{"messages": [{"role": "user", "content": "hello"}]}'
```

### Check Vercel Logs for CLM
```bash
vercel logs simple-clm --follow
```

### Check Railway Logs
```bash
railway logs --follow
```

### Common Errors

| Error | Cause | Fix |
|-------|-------|-----|
| "Illegal header value" | Newline in API key | Re-add env var without trailing `\n` |
| 404 from agent | Auth protection or wrong URL | Check Railway URL, remove Vercel auth |
| Silent voice | CLM returning JSON not SSE | Use `StreamingResponse` |
| "I don't have access" | Hume using its own LLM | Enable CLM-only mode in dashboard |

---

# Key Concepts Explained

## AG-UI vs A2UI vs CopilotRuntime

| Term | What It Is | Do We Use It? |
|------|------------|---------------|
| **AG-UI** | "Agent-to-UI" protocol - streaming format for agent â†” frontend communication | **Yes** - via `agent.to_ag_ui()` |
| **A2UI** | Google's version of same concept, CopilotKit supports both | Same as AG-UI |
| **CopilotRuntime** | CopilotKit's backend proxy (handles LLM calls, tools) | **No** - we have our own Pydantic AI agent |
| **Copilot Cloud** | CopilotKit's hosted CopilotRuntime service | **No** - we self-host |

### Why We Don't Need CopilotRuntime

CopilotRuntime is for apps that want CopilotKit to handle LLM calls. Since we have a **custom Pydantic AI agent** with tools, database access, and Zep memory, we bypass CopilotRuntime entirely:

```
Typical CopilotKit App:
  Frontend â†’ CopilotRuntime â†’ LLM

Our App:
  Frontend â†’ Pydantic AI Agent â†’ LLM
           (via AG-UI protocol)
```

## Generative UI (Charts in Chat)

When the agent returns tool results, the frontend renders custom React components. This is **dynamic** - data comes from real-time database queries.

**Flow:**
```
1. User: "Show job distribution"
2. Agent calls: show_jobs_chart() â†’ queries Neon DB
3. Agent returns: { chartData: [...], title: "..." }
4. AG-UI streams: tool_result event to frontend
5. Frontend: useRenderToolCall renders <BarChart />
6. User sees: Live chart with real data
```

**Frontend code pattern:**
```typescript
useRenderToolCall({
  name: "show_jobs_chart",
  render: ({ result }) => <BarChart data={result.chartData} />
})
```

## What Lives Where

```
YOUR DEPLOYMENTS:
â”œâ”€â”€ Vercel: copilotkit-demo
â”‚   â”œâ”€â”€ Next.js frontend
â”‚   â”œâ”€â”€ CopilotKit React components (library, runs in browser)
â”‚   â”œâ”€â”€ API routes (/api/hume-token, /api/zep-context, etc.)
â”‚   â””â”€â”€ NO CopilotRuntime needed
â”‚
â””â”€â”€ Railway: unified-agent (TO BE DEPLOYED)
    â”œâ”€â”€ Pydantic AI agent (the brain)
    â”œâ”€â”€ AG-UI endpoint (for CopilotKit)
    â””â”€â”€ CLM endpoint (for Hume voice)

EXTERNAL SERVICES (not your hosting):
â”œâ”€â”€ Zep Cloud: api.getzep.com (memory/facts)
â”œâ”€â”€ Neon Cloud: *.neon.tech (PostgreSQL database)
â”œâ”€â”€ Hume AI: (voice interface)
â””â”€â”€ Google AI: (Gemini LLM)
```

---

# Next Session: Railway Deployment Plan

## Goal
Deploy unified Python service to Railway with both AG-UI and CLM endpoints.

## Files to Create/Modify

### 1. Create `agent/Procfile`
```
web: uvicorn src.agent:app --host 0.0.0.0 --port $PORT
```

### 2. Modify `agent/src/agent.py`
Add CLM endpoint to the same FastAPI app:
```python
from fastapi import FastAPI, Request
from starlette.responses import StreamingResponse

# Existing agent
agent = Agent(...)
ag_ui_app = agent.to_ag_ui(deps=...)

# New: Main app with CLM endpoint
main_app = FastAPI()

@main_app.post("/chat/completions")
async def clm_endpoint(request: Request):
    # Parse Hume request, call agent, return SSE stream
    ...

# Mount AG-UI at root
main_app.mount("/", ag_ui_app)

app = main_app  # Export this
```

### 3. Set Railway Environment Variables
```
DATABASE_URL=postgresql://...@neon.tech/neondb
ZEP_API_KEY=z_...
GOOGLE_API_KEY=...
```

### 4. Update Hume Dashboard
Change CLM URL from `simple-clm.vercel.app` to Railway URL

### 5. Update CopilotKit Frontend
Point `agentUrl` to Railway URL

## Deployment Steps
1. Create Procfile
2. Add CLM endpoint to agent.py
3. Push to GitHub
4. Create/link Railway project
5. Set env vars
6. Deploy
7. Get public URL
8. Update Hume config
9. Update frontend config
10. Test voice + chat

## Success Criteria
- [ ] Voice: "What's my name?" â†’ Agent responds with user's name
- [ ] Chat: Same query â†’ Same response
- [ ] Onboarding: New user gets profile questions
- [ ] Charts: "Show job distribution" â†’ Live chart renders

---

# Code Health Assessment (Jan 2025)

## Status: MVP-Ready âœ…

The code is **production-ready for MVP**. Deploy first, refactor later.

## Known Issues (Non-Blocking)

| Issue | Impact | Action |
|-------|--------|--------|
| No DB connection pooling | Performance (not critical) | Add asyncpg pool later |
| 957-line agent.py | Maintainability | Split into modules later |
| Mixed sync/async tools | Inconsistency | Standardize later |

## CLM Consolidation Pattern

When adding CLM endpoint to agent.py, use this pattern:

```python
# At top of agent.py
from fastapi import FastAPI, Request
from starlette.responses import StreamingResponse
import json

# Create main FastAPI app
main_app = FastAPI()

# === CLM ENDPOINT FOR HUME ===
async def stream_sse_response(content: str, msg_id: str):
    """Stream OpenAI-compatible SSE chunks for Hume."""
    words = content.split(' ')
    for i, word in enumerate(words):
        chunk = {
            "id": msg_id,
            "object": "chat.completion.chunk",
            "choices": [{
                "index": 0,
                "delta": {"content": word + (' ' if i < len(words) - 1 else '')},
                "finish_reason": None
            }]
        }
        yield f"data: {json.dumps(chunk)}\n\n"

    yield f"data: {json.dumps({'choices': [{'delta': {}, 'finish_reason': 'stop'}]})}\n\n"
    yield "data: [DONE]\n\n"

@main_app.post("/chat/completions")
async def clm_endpoint(request: Request):
    """OpenAI-compatible endpoint for Hume EVI."""
    body = await request.json()
    messages = body.get("messages", [])

    # Extract user message
    user_msg = next((m["content"] for m in reversed(messages) if m["role"] == "user"), "")

    # Parse session ID: "firstName|fractional_userId|location:London,jobs:25"
    # (Copy parsing logic from simple-clm/api/index.py)

    # TODO: Call agent with user context and get response
    # For now, use the same fallback logic as simple-clm

    response_text = f"Hello! You said: {user_msg}"
    msg_id = f"clm-{hash(user_msg)}"

    return StreamingResponse(
        stream_sse_response(response_text, msg_id),
        media_type="text/event-stream"
    )

# === EXISTING AGENT CODE ===
# ... (all existing agent definition, tools, etc.)

# === AG-UI APP ===
ag_ui_app = agent.to_ag_ui(deps=StateDeps(AppState()))

# Mount AG-UI under the main app
main_app.mount("/ag-ui", ag_ui_app)

# Export main_app instead of ag_ui_app
app = main_app
```

**Key Points:**
- CLM at `/chat/completions` for Hume
- AG-UI at `/ag-ui` (or `/`) for CopilotKit
- Same agent handles both
- Copy SSE streaming from `simple-clm/api/index.py`

## Future Refactoring (Post-MVP)

```
agent/src/
â”œâ”€â”€ agent.py          # Agent definition only
â”œâ”€â”€ models.py         # Pydantic models
â”œâ”€â”€ zep_client.py     # Zep integration
â”œâ”€â”€ db.py             # Connection pool
â”œâ”€â”€ clm.py            # CLM endpoint
â””â”€â”€ tools/            # One file per tool category
```

---

# Session Learnings: 2025-01-06 (Night) - Profile Building System

## What We Built This Session

### 1. Live Profile Graph Component
**File**: `src/components/LiveProfileGraph.tsx`

A real-time profile visualization that shows:
- 3D force graph on the left (visual)
- Text list on the right (Blade Runner style) with labels
- Edit/delete buttons on hover
- Green pulse animation when data updates
- User name in header with gold dot

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â— Dan                           4 items    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                   â”‚ LOCATION               â”‚
â”‚    [3D Graph]     â”‚ â— London               â”‚
â”‚                   â”‚                        â”‚
â”‚                   â”‚ TARGET ROLE            â”‚
â”‚                   â”‚ â— CMO                  â”‚
â”‚                   â”‚                        â”‚
â”‚                   â”‚ COMPANY                â”‚
â”‚                   â”‚ â— Sony (CMO) âœ“         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â— Location  â— Role  â— Company  â— Skill     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. User Profile Items Table (Neon)
**Table**: `user_profile_items`

```sql
CREATE TABLE user_profile_items (
  id SERIAL PRIMARY KEY,
  user_id TEXT NOT NULL,
  item_type TEXT NOT NULL,  -- 'location', 'role_preference', 'company', 'skill'
  value TEXT NOT NULL,
  metadata JSONB DEFAULT '{}',  -- company_url, job_title, etc.
  confirmed BOOLEAN DEFAULT false,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW(),
  UNIQUE(user_id, item_type, value)
);
```

### 3. Profile API Endpoints
**File**: `src/app/api/user-profile/route.ts`

| Method | Purpose |
|--------|---------|
| GET | Fetch user's profile items |
| POST | Save/update profile item (upsert) |
| DELETE | Remove profile item |

### 4. Single vs Multi-Value Fields

**Single-value** (only ONE allowed, new replaces old):
- `location` - User's base location
- `role_preference` - Target role (CMO, CTO, etc.)

**Multi-value** (can have many):
- `skill` - Multiple skills allowed
- `company` - Multiple companies (past + current)

When saving a single-value field, the agent:
1. Checks if one exists
2. If same value â†’ no change
3. If different â†’ deletes old, inserts new
4. Returns `{ replaced: "old_value" }` for confirmation

### 5. Human-in-the-Loop: Company Confirmation
**Frontend**: `useHumanInTheLoop` hook for `confirm_company`

Flow:
1. User says "I work at Sony"
2. Agent calls `confirm_company(company_name="Sony", company_url="https://www.sony.com")`
3. HITL popup appears with:
   - Company name
   - URL link for verification
   - Job title input field
   - Confirm/Reject buttons
4. On confirm â†’ saves to Neon with `confirmed: true`
5. Graph updates with green pulse

### 6. Direct Database Saves (Fixed)
**Problem**: Agent's `save_user_preference` was calling `http://localhost:3000/api/user-profile` which doesn't work from Railway.

**Fix**: Save directly to Neon using psycopg2:
```python
conn = psycopg2.connect(DATABASE_URL)
cur = conn.cursor()
cur.execute("""
  INSERT INTO user_profile_items (user_id, item_type, value, metadata, confirmed)
  VALUES (%s, %s, %s, %s, %s)
  ON CONFLICT (user_id, item_type, value) DO UPDATE SET updated_at = NOW()
""", (user.id, item_type, value, '{"source": "voice_detected"}', False))
conn.commit()
```

---

## Challenges & Solutions

### Challenge 1: Graph showing raw Zep facts
**Problem**: Graph displayed verbose text like "User 5e421f23... expressed interest in..."
**Solution**: Entity extraction function that parses facts into clean labels (London, CTO, Sony)

### Challenge 2: HITL not triggering for company
**Problem**: Backend `confirm_company` tool was shadowing frontend HITL
**Solution**: Removed backend tool, frontend `useHumanInTheLoop` now receives calls

### Challenge 3: Job title input not working in CopilotKit sidebar
**Problem**: CopilotKit sidebar intercepting keyboard events
**Solution**: Added `onKeyDown={(e) => e.stopPropagation()}` to input

### Challenge 4: save_user_preference not saving
**Problem**: API call to localhost failing from Railway
**Solution**: Direct psycopg2 database save instead of HTTP call

### Challenge 5: Duplicate locations
**Problem**: Multiple location entries (Manchester twice, London twice)
**Solution**: Single-value fields now delete existing before insert

---

## Current State (What Works)

| Feature | Status | Notes |
|---------|--------|-------|
| CopilotKit chat | âœ… Working | Charts, jobs render correctly |
| Voice (Hume) | âœ… Working | CLM on Railway responds |
| Profile graph | âœ… Working | Shows Neon data, updates live |
| Company HITL | âš ï¸ Partial | Popup shows, input may need testing |
| save_user_preference | ğŸ”„ Deploying | Direct DB save just pushed |
| Single-value replace | ğŸ”„ Deploying | Just pushed |

---

## Deployment URLs

| Service | URL | Purpose |
|---------|-----|---------|
| Frontend | Vercel (auto) | Next.js, CopilotKit |
| Agent | `copilotkit-agent-production.up.railway.app` | Pydantic AI, CLM |
| Database | Neon `ep-wandering-darkness-abiq57ia` | PostgreSQL |
| Voice | Hume Config `acb5575c-e22f-44c0-a9c8-b03305d1ea92` | EVI |

---

## Files Modified This Session

| File | Changes |
|------|---------|
| `src/components/LiveProfileGraph.tsx` | New component - graph + text list |
| `src/app/api/user-profile/route.ts` | New API - GET/POST/DELETE |
| `src/app/page.tsx` | Added LiveProfileGraph, company HITL, input fix |
| `agent/src/agent.py` | save_user_preference direct DB, single-value logic, removed backend confirm_company |

---

## Next Steps (Priority Order)

1. **Test save_user_preference** - Say "I'm in Manchester" via voice, check if it saves
2. **Test company HITL** - Say "I work at Google", verify popup + input works
3. **Verify single-value replace** - Say "Actually I'm in London" â†’ should replace Manchester
4. **Add onboarding prompts** - Agent should ASK for missing profile info
5. **URL validation for companies** - Actually verify company URLs exist

---

## User ID for Testing
```
Dan Keegan: 5e421f23-16a6-42de-a4a4-fa412414f1d8
```

---

## Quick Debug Commands

```bash
# Check profile items in Neon
node -e "
const { neon } = require('@neondatabase/serverless');
const sql = neon(process.env.DATABASE_URL);
sql\`SELECT * FROM user_profile_items WHERE user_id = '5e421f23-16a6-42de-a4a4-fa412414f1d8'\`.then(console.log);
"

# Check Railway logs for save attempts
railway logs | grep -i "save\|preference\|ğŸ’¾"

# Deploy agent to Railway
cd agent && railway up

# Check agent is responding
curl -s https://copilotkit-agent-production.up.railway.app/health
```

---

# Session Learnings: 2025-01-07 - Fractional Quest v2 Migration

## Current State Summary

### What's Working âœ…
- **CopilotKit chat** - Works on homepage with charts, jobs, graphs
- **Voice (Hume)** - CLM on Railway responds correctly
- **Profile graph** - Shows Neon data, updates live
- **Design system** - Unified CSS in globals.css, Playfair Display fonts
- **Job pages** - `/fractional-jobs-london`, `/fractional-jobs-uk`, `/fractional-cfo-jobs-uk`
- **SEO components** - FAQ, WebPageSchema, FAQPageSchema ported

### What Was Just Built (This Session)
- **ServicesTemplate** - Reusable template for hire-fractional-* pages
- **/hire-fractional-cmo** - First services page using new template
- **Hero styling fixed** - Gradient background, white H1

### Outstanding Issues âš ï¸

#### 1. Hydration Mismatch (WebPageSchema)
**File**: `src/components/seo/WebPageSchema.tsx:37`
```tsx
// PROBLEM: Server and client render different dates
dateModified={new Date()}  // Called in ServicesTemplate
```
**Fix needed**: Use a static date or generate at build time

#### 2. Page Context Not Reaching Agent
**Problem**: Agent says "we are currently on the main page" even on /hire-fractional-cmo
**Root cause**: The `instructions` prop on CopilotSidebar isn't being extracted by the agent middleware

**File**: `src/components/templates/ServicesTemplate.tsx:219-237`
```tsx
<CopilotSidebar
  instructions={`## Service Page Context: Fractional ${roleType}
  You're helping someone learn about our Fractional ${roleType} services...`}
/>
```

**Agent needs**: Middleware to extract page context from system messages
**Pattern exists**: See "CRITICAL: Passing User Context to Pydantic AI Agent" section above

---

## Pages Inventory

### Existing in copilotkit-demo
| Page | Status | Notes |
|------|--------|-------|
| `/` (homepage) | âœ… Working | Full CopilotKit + Voice |
| `/fractional-jobs-london` | âœ… Working | SEO page with jobs |
| `/fractional-jobs-uk` | âœ… Working | SEO page with jobs |
| `/fractional-cfo-jobs-uk` | âœ… Working | SEO page with jobs |
| `/hire-fractional-cmo` | âš ï¸ Partial | Template done, context issue |
| `/profile` | âœ… Working | User profile page |
| `/dashboard` | âœ… Working | Admin dashboard |

### To Build (From fractional.quest)
**Services Pages (Priority 1 - No SEO risk)**
- `/hire-fractional-cto`
- `/hire-fractional-cfo`
- `/hire-fractional-coo`

**Jobs UK Pages (Priority 2 - Preserve SEO)**
- `/fractional-cmo-jobs-uk` (15 clicks/day)
- `/fractional-cto-jobs-uk` (14 clicks/day)
- `/fractional-coo-jobs-uk` (11 clicks/day)
- `/london` (40 clicks/day - HIGH PRIORITY)

---

## Next Steps (Priority Order)

### Phase 1: Fix Current Issues
1. **Fix hydration error** - Use static date in WebPageSchema
2. **Fix page context** - Add page_context parsing to agent middleware
3. **Test voice on /hire-fractional-cmo** - Verify it's contextually aware

### Phase 2: Complete Services Pages
4. Create `/hire-fractional-cto` using ServicesTemplate
5. Create `/hire-fractional-cfo` using ServicesTemplate
6. Create `/hire-fractional-coo` using ServicesTemplate

### Phase 3: Recreate High-Traffic Jobs Pages
7. Create `/fractional-cmo-jobs-uk` (preserve SEO from v1)
8. Create `/fractional-cto-jobs-uk`
9. Create `/fractional-coo-jobs-uk`
10. Create `/london` (40 clicks - high priority!)

---

## Key Files Reference

### Frontend (Next.js)
| File | Purpose |
|------|---------|
| `src/app/globals.css` | Unified design system |
| `src/app/layout.tsx` | Fonts (Geist, Playfair) |
| `src/components/templates/ServicesTemplate.tsx` | Services page template |
| `src/components/seo/FAQ.tsx` | FAQ accordion + FAQ arrays |
| `src/components/seo/WebPageSchema.tsx` | JSON-LD schema |
| `src/components/voice-input.tsx` | Hume voice widget |

### Backend (Pydantic AI)
| File | Purpose |
|------|---------|
| `agent/src/agent.py` | Main agent with tools, middleware |

### Database
- **Table**: `jobs` - All job listings
- **Table**: `user_profile_items` - User preferences

---

## Quick Debug Commands

```bash
# Run frontend
npm run dev

# Run agent locally
cd agent && uv run uvicorn src.agent:app --reload --port 8000

# Check build
npm run build

# View page
open http://localhost:3000/hire-fractional-cmo
```

---

# Session Learnings: 2025-01-06 (Continued) - Bug Fixes

## Issues Fixed This Session

### 1. Company Saved as Skill Bug âœ…
**Problem**: When user said "I used to work at Sony PlayStation", agent called `save_user_preference("skill", "sony playstation")` instead of `confirm_company`.

**Root Cause**: Agent prompt only had limited trigger phrases ("I work at", "I was at", "Currently at") but missed "used to work at", "previously at", etc.

**Fix** (`agent/src/agent.py` lines 293-326):
```python
## COMPANY CONFIRMATION (Human-in-the-Loop)
CRITICAL: When user mentions ANY company they work/worked at, call confirm_company!

**Trigger phrases** (ANY of these â†’ confirm_company):
- "I work at [X]"
- "I worked at [X]"
- "I used to work at [X]"
- "I was at [X]"
- "Previously at [X]"
- "Currently at [X]"
- "I'm at [X]"
- "I joined [X]"
- "My company is [X]"
- "I left [X]"
- "Former [X] employee"

âš ï¸ NEVER save company names using save_user_preference("skill", ...)!
Companies are NOT skills. Always use confirm_company for employment history.
```

**Verified**: Agent now calls `confirm_company` for "I used to work at Sony PlayStation"

### 2. Case Sensitivity Causing Duplicates âœ…
**Problem**: "Manchester" and "manchester" were stored as separate entries because:
- UNIQUE constraint on (user_id, item_type, value) is case-sensitive
- No normalization before INSERT

**Fix** (`agent/src/agent.py` lines 573-588):
```python
def normalize_value(val: str, typ: str) -> str:
    """Normalize values to consistent case."""
    if typ == "location":
        # Title case for locations: "manchester" â†’ "Manchester"
        return val.strip().title()
    elif typ == "role_preference":
        # Uppercase for roles: "cto" â†’ "CTO"
        return val.strip().upper()
    elif typ == "skill":
        # Title case for skills: "python" â†’ "Python"
        return val.strip().title()
    else:
        return val.strip()

normalized_value = normalize_value(value, item_type)
```

**Verified**: Input "manchester" is now stored as "Manchester"

### 3. Cleaned Up Bad Test Data âœ…
- Deleted duplicate location entries (id 1, 3)
- Deleted orphan entry with user_id "unknown"
- Removed incorrectly saved "skill: technology"

## Current Profile State (Dan Keegan)

```
id=5  location: London
id=6  role_preference: CMO
id=7  company: Sony (confirmed)
id=8  skill: Marketing
```

## Updated Current State

| Feature | Status | Notes |
|---------|--------|-------|
| CopilotKit chat | âœ… Working | Charts, jobs render correctly |
| Voice (Hume) | âœ… Working | CLM on Railway responds |
| Profile graph | âœ… Working | Shows Neon data, updates live |
| Company HITL | âœ… Working | Triggers correctly for "work at" phrases |
| save_user_preference | âœ… Working | Direct DB save with case normalization |
| Single-value replace | âœ… Working | DELETE old â†’ INSERT new |
| Case normalization | âœ… Working | Prevents duplicates |

## Files Modified This Session

| File | Changes |
|------|---------|
| `agent/src/agent.py` | Company detection prompt expansion, normalize_value() function |

---

# Session Learnings: 2025-01-07 (Continued) - Content Migration Progress

## What Was Completed This Session

### New Pages Created (16 pages total):

**CHRO Role (4 pages):**
- `/fractional-chro-jobs-uk/page.tsx` - Jobs UK page (purple theme)
- `/fractional-chro/page.tsx` - Role definition page
- `/fractional-chro-salary/page.tsx` - Salary guide page
- `/hire-fractional-chro/page.tsx` - Hiring guide page

**CEO Role (4 pages):**
- `/fractional-ceo-jobs-uk/page.tsx` - Jobs UK page (yellow/gold theme)
- `/fractional-ceo/page.tsx` - Role definition page
- `/fractional-ceo-salary/page.tsx` - Salary guide page
- `/hire-fractional-ceo/page.tsx` - Hiring guide page

**CPO Role (4 pages):**
- `/fractional-cpo-jobs-uk/page.tsx` - Jobs UK page (indigo theme)
- `/fractional-cpo/page.tsx` - Role definition page
- `/fractional-cpo-salary/page.tsx` - Salary guide page
- `/hire-fractional-cpo/page.tsx` - Hiring guide page

**CISO Role (4 pages):**
- `/fractional-ciso-jobs-uk/page.tsx` - Jobs UK page (red theme)
- `/fractional-ciso/page.tsx` - Role definition page
- `/fractional-ciso-salary/page.tsx` - Salary guide page
- `/hire-fractional-ciso/page.tsx` - Hiring guide page

### Audit Fixes Applied to New Pages:

After creating pages, an audit compared them to original fractional.quest pages. These improvements were applied to CHRO, CEO, CPO, CISO pages:

1. **Jobs UK pages** - Added:
   - Internal links to role definition, salary guide, hiring guide
   - External authority links (CIPD, IOD, NCSC, etc.)
   - Location-based job search grid (London, Manchester, etc.)

2. **Role Definition pages** - Added:
   - Expanded Related Resources (3 cards including hiring guide)
   - External Resources section with professional body links

3. **Salary pages** - Added:
   - 4 resource cards (including hiring guide)
   - External Salary Resources links (Glassdoor, HMRC, etc.)

### FAQs Added:

Added to `/src/components/seo/FAQ.tsx`:
- `CHRO_FAQS` - 5 questions about fractional CHRO
- `CEO_FAQS` - 5 questions about fractional CEO
- `CPO_FAQS` - 5 questions about fractional CPO
- `CISO_FAQS` - 5 questions about fractional CISO

### Components Modified:

- `RoleContentHub.tsx` - Added 'cpo' to type definition

### Git Commits:

1. `2f08c57` - Add Jobs UK pages for CHRO, CEO, CPO, and CISO roles
2. `71a7dee` - Add role definition pages for CHRO, CEO, CPO, and CISO
3. `179a218` - Add salary guide pages for CHRO, CEO, CPO, and CISO
4. `a336bae` - Add hiring guide pages for CHRO, CEO, CPO, and CISO
5. `1b6e0e6` - Improve internal linking and resources on CHRO, CEO, CPO, CISO pages
6. `fff6b56` - Add content migration plan documentation

---

## What Still Needs To Be Done

### Priority 1: Apply Audit Fixes to Original Pages

The CMO, CTO, CFO, COO pages exist but need the same internal/external link improvements that were applied to CHRO, CEO, CPO, CISO pages.

**Files to update (12 files total):**

| Role | Jobs UK | Definition | Salary |
|------|---------|------------|--------|
| CMO | `fractional-cmo-jobs-uk/page.tsx` | `fractional-cmo/page.tsx` | `fractional-cmo-salary/page.tsx` |
| CTO | `fractional-cto-jobs-uk/page.tsx` | `fractional-cto/page.tsx` | `fractional-cto-salary/page.tsx` |
| CFO | `fractional-cfo-jobs-uk/page.tsx` | `fractional-cfo/page.tsx` | `fractional-cfo-salary/page.tsx` |
| COO | `fractional-coo-jobs-uk/page.tsx` | `fractional-coo/page.tsx` | `fractional-coo-salary/page.tsx` |

**Changes needed for each:**

1. **Jobs UK pages**: Add editorial section with internal links + external authority links + location grid (copy pattern from `fractional-chro-jobs-uk/page.tsx`)

2. **Role Definition pages**: Expand Related Resources from 2â†’3 cards, add External Resources section (copy pattern from `fractional-chro/page.tsx`)

3. **Salary pages**: Expand Related Resources from 3â†’4 cards, add External Salary Resources (copy pattern from `fractional-chro-salary/page.tsx`)

### External Authority Links by Role:

| Role | Links to Add |
|------|-------------|
| CMO | CIM (Chartered Institute of Marketing), DMA (Data & Marketing Association), Marketing Week |
| CTO | BCS (British Computer Society), IET, Tech Nation |
| CFO | ICAEW, ACCA, CIMA, FRC |
| COO | IOD, CMI (Chartered Management Institute), CIPS |

---

## Reference Files (Copy Patterns From These)

When updating CMO, CTO, CFO, COO pages, copy the exact pattern from:

- **Jobs UK links**: `/src/app/fractional-chro-jobs-uk/page.tsx` lines 160-195
- **Role definition resources**: `/src/app/fractional-chro/page.tsx` lines 155-208
- **Salary resources**: `/src/app/fractional-chro-salary/page.tsx` lines 164-199

---

## Content Plan Location

Full content migration plan with checklists: `/Users/dankeegan/copilotkit-demo/CONTENT_PLAN.md`
